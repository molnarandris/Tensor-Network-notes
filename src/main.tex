\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{amsthm,amsmath,amssymb}
\usepackage{tikz}
\usepackage[hidelinks,draft=false,colorlinks=true]{hyperref}
\usepackage[capitalize]{cleveref} % after hyperref!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% For bibliography
\usepackage[sorting=none, backend=biber, url=false, isbn=false, hyperref=true, eprint=true, maxbibnames=6]{biblatex}
\addbibresource{/home/molnar/Dropbox/ZoteroLibrary.bib}
\AtEveryBibitem{%
	\clearfield{eprintclass}%
}

% Setting title to point to doi link
\ExecuteBibliographyOptions{doi=false}
\newbibmacro{string+doi}[1]{%
	\iffieldundef{doi}{#1}{\href{http://dx.doi.org/\thefield{doi}}{#1}}}
\DeclareFieldFormat{title}{\usebibmacro{string+doi}{\mkbibemph{#1}}}
\DeclareFieldFormat[article]{title}{\usebibmacro{string+doi}{\mkbibquote{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% hyperref setup
\hypersetup{
	pdftitle={Tensor Networks},
	pdfauthor={Andras Molnar},
	bookmarks=true,
	bookmarksnumbered=true,
	bookmarksopen=true,
	bookmarksopenlevel=1,
	colorlinks,
	%linkcolor=blue!50!black,
	%urlcolor=cyan!50!black!90,
	pdfstartview=Fit,
	pdfpagemode=UseOutlines,    
	pdfpagelayout=TwoPageRight
}

\newtheorem{lemma}{Lemma}
\newtheorem{fact}{Fact}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}


\newcommand{\tr}{\operatorname{Tr}}
\newcommand{\id}{\mathrm{Id}}
\newcommand{\todo}[1]{{\color{red} #1}}
\newcommand{\myfcn}{nice }
\newcommand{\myfcntwo}{admissible }
\newcommand{\End}{\mathrm{End}}
\newcommand{\ket}[1]{\vert #1 \rangle}
\newcommand{\bra}[1]{\langle #1 \vert}
\newcommand{\scalprod}[2]{\langle #1 \vert #2 \rangle}
\newcommand{\Span}{\mathrm{Span}}


\tikzset{
	tensor/.style={
		inner sep = 0.055cm,
		shape = circle,
		draw,
		fill
	},
	t/.style={
		inner sep = 0.03cm,
		shape = circle,
		draw,
		fill
	},
}

\tikzset{>=stealth}


\title{Tensor Networks}
\author{Andras Molnar}

\begin{document}

\maketitle

\begin{remark}
	In these notes all vector spaces are complex and finite dimensional unless otherwise stated.
\end{remark}


\section{Matrix Product States (MPS)}

\begin{definition}[MPS]
  Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space with basis $\mathcal{B} = \{\ket{0},\ket{1},\dots \ket{d-1}\}$. A tensor $A\in \End(V)\otimes \mathcal{H}$, $A = \sum_{i\in \mathcal{B}} A_i \otimes \ket{i}$ is called an MPS tensor. The translation invariant (TI) MPS on $n$ sites is a state $\mathfrak{M}_n(A)\in \mathcal{H}^{\otimes n}$ defined by
  \begin{equation*}
  	\mathfrak{M}_n(A) = \sum_{i\in \mathcal{B}^n} \tr\left\{A_{i_1} A_{i_2} \dots A_{i_n}\right\} \ket{i_1 i_2 \dots i_n}.
  \end{equation*}
  We call $V$ the bond space and $\dim(V)$ the bond dimension of the MPS.
\end{definition}

A class of MPS, called injective MPS, is going to play a crucial role in the theory of MPS. We will prove that any TI MPS -- after blocking -- decomposes into a sum of injective MPS. The parent Hamiltonian of an injective MPS is gapped and the MPS is its unique ground state. Two injective MPS are either orthogonal in the thermodynamic limit or are generating the same state for all system sizes. If they generate the same state for a large enough system size, then the two MPS tensors are related to each other by a gauge transformation. 

We will use all these statements to understand the classification of phases in 1D spin systems, with and without symmetries. 

To define injective MPS, we introduce MPS with arbitrary boundary condition:
\begin{definition}[MPS with boundary]
  Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space with basis $\mathcal{B} = \{\ket{0},\ket{1},\dots \ket{d-1}\}$. A tensor $A\in \End(V)\otimes \mathcal{H}$, $A = \sum_{i\in \mathcal{B}} A_i \otimes \ket{i}$ is called an MPS tensor. The MPS on $n$ sites with a given boundary condition $X$ is a state $\mathfrak{M}_n(A,X)\in \mathcal{H}^{\otimes n}$ defined by
  \begin{equation*}
    \mathfrak{M}_n(A,X) = \sum_{i\in \mathcal{B}^n} \tr\left\{A_{i_1} A_{i_2} \dots A_{i_n}\right\} \ket{i_1 i_2 \dots i_n}.
  \end{equation*}
\end{definition}

Notice that the periodic boundary condition MPS $\mathfrak{M}_n(A)$ can also be written as $\mathfrak{M}_n(A) = \mathfrak{M}_n(A,\id)$.

\begin{definition}[Injective MPS]
  Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space. An MPS tensor $A\in \End(V)\otimes \mathcal{H}$ is called \emph{injective} if $\exists n\in\mathbb{N}$ s.t the map $X\mapsto \mathfrak{M}_n(A,X)$ is injective.
\end{definition}

\begin{theorem}\label{thm:injectivity_equivalent}
  Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space with basis $\mathcal{B} = \{\ket{0},\ket{1},\dots \ket{d-1}\}$. The MPS tensor $A\in \End(V)\otimes \mathcal{H}$, $A = \sum_{i\in \mathcal{B}} A_i \otimes \ket{i}$, is injective if and only if $\exists n\in \mathbb{N}$ s.t.
  \begin{equation*}
  	\Span\left\{A_{i_1} A_{i_2} \dots A_{i_n} \middle| i\in \mathcal{B}^n \right\} = \End(V).
  \end{equation*}
\end{theorem}

\begin{proof}
	Let $S_n = \Span\left\{A_{i_1} A_{i_2} \dots A_{i_n} \middle| i\in \mathcal{B}^n \right\}$. Notice that $\mathfrak{M}_n(A,X)=0$ is equivalent to $\tr\{XY\} = 0$ $\forall Y\in S_n$.
  
  Assume now that $S_n = \End(V)$. Then $\mathfrak{M}_n(A,X) = 0$ is equivalent to $\tr \{XY\} = 0 $ $\forall Y\in \End(V)$. As the bilinear functional $(X,Y)\mapsto \tr (XY)$ is non-degenerate, this implies $X=0$, i.e.\ the MPS is injective.
  
  For the other direction, we need to show that $S_n\subsetneq \End(V)$ implies that $A$ is not injective. As the bilinear functional $(X,Y)\mapsto \tr (XY)$ is non-degenerate, $\exists X\neq 0$ such that $\tr (XY) = 0 \ \forall Y\in S_n$, and thus $\mathfrak{M}_n(A,X) = 0$, i.e.\ the MPS is not injective.
\end{proof}


\begin{theorem}
  Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space, and let $A\in \End(V)\otimes \mathcal{H}$ be an MPS tensor. Then, if $X\mapsto\mathfrak{M}_n(A,X)$ is injective for some $n\in\mathbb{N}$, then $X \mapsto \mathfrak{M}_k(A,X)$ is injective as well for any $k\geq n$.
\end{theorem}

\begin{proof}
  Let $S_n = \Span\left\{A_{i_1} A_{i_2} \dots A_{i_n} \middle| i\in \mathcal{B}^n \right\}$. Using \cref{thm:injectivity_equivalent}, $\psi_n$ is injective if and only if $S_n = \End(V)$. It is enough to show thus that if $S_n = \End(V)$, then $S_{n+1} = \End(V)$ as well. Notice that $S_{n+1} = \Span\{S_1 S_n\} = \Span\{ S_1 \End(V)\}$, and that $S_{n} = \Span\{S_1 S_{n-1}\} \subseteq \Span\{S_1 \End(V)\}$. Therefore $S_{n+1} \supseteq S_n = \End(V)$, i.e.\ $S_{n+1} = \End(V)$. 
\end{proof}

\begin{definition}[Injectivity length]
    Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space. Let $A\in \End(V)\otimes \mathcal{H}$ be an \emph{injective} MPS tensor. The minimal $n$ for which the map $X\mapsto \mathfrak{M}_n(A,X)$ is injective is called the \emph{injectivity length} of $A$.
\end{definition}

\begin{lemma}\label{lem:injective_l_r_inverse}
  Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space with basis $\mathcal{B} = \{\ket{0},\ket{1},\dots \ket{d-1}\}$. Let $A\in \End(V)\otimes \mathcal{H}$, $A = \sum_{i\in \mathcal{B}} A_i \otimes \ket{i}$, be an injective tensor. Then there are $l_j\in \End(V)$ and $r_j \in \End(V)$ ($j\in\mathcal{B}$) such that
  \begin{equation*}
    \sum_j A_j r_j = \sum_j l_j A_j = \id.
  \end{equation*} 
\end{lemma}
\begin{proof}
  Injectivity of $A$ implies that there is $n\in\mathbb{N}$ such that $\id\in\End(V) = \Span\left\{A_{i_1} A_{i_2} \dots A_{i_n} \middle| i\in \mathcal{B}^n \right\}$, that is, there is  $c_{i_1\dots i_n}$ such that $\sum_i c_{i_1 \dots i_n} A_{i_1}\dots A_{i_n} = \id$. We can thus set $r_j = \sum_{i_2 \dots i_n} c_{ji_2\dots i_n} A_{i_2}\dots A_{i_n}$ and $l_j = \sum_{i_1 \dots i_{n-1}} c_{i_1\dots i_{n-1}j} A_{i_1}\dots A_{i_{n-1}}$. 
\end{proof}



\begin{remark}
  Let $V_A, V_B$ be two vector spaces and $\mathcal{H}$ be a Hilbert space with basis $\mathcal{B} = \{\ket{0},\ket{1},\dots \ket{d-1}\}$. Let $A\in \End(V_A)\otimes \mathcal{H}$, $A = \sum_{i\in \mathcal{B}} A_i \otimes \ket{i}$, and $B\in \End(V_B)\otimes \mathcal{H}$, $B = \sum_{i\in \mathcal{B}} B_i \otimes \ket{i}$, be two MPS tensors, such that 
  \begin{equation}\label{eq:gauge_1}
    B_i = X A_i X^{-1} \quad \forall i = \{0,1,\dots d-1\}.
  \end{equation}
  Then for all $n\in\mathbb{N}$, $\mathfrak{M}_n(A) = \mathfrak{M}_n(B)$.
\end{remark}

\begin{proof}
  \begin{equation*}
    \mathfrak{M}_n(B) = \sum_{i\in \mathcal{B}^n} \tr\left\{B_{i_1} B_{i_2} \dots B_{i_n}\right\} \ket{i_1 i_2 \dots i_n}.
  \end{equation*}
  Using now \cref{eq:gauge_1}, we obtain   
  \begin{equation*}
    \mathfrak{M}_n(B) = \sum_{i\in \mathcal{B}^n} \tr\left\{XA_{i_1}X^{-1} XA_{i_2}X^{-1} \dots XA_{i_n}X^{-1}\right\} \ket{i_1 i_2 \dots i_n}.
  \end{equation*}
  Noticing that between two MPS tensors $X^{-1}X=\id$ (and using cyclicity of the trace), we directly obtain  that $\mathfrak{M}_n(B) = \mathfrak{M}_n(A)$.
\end{proof}

Under certain conditions the statement can be reversed: if two MPS tensors $A$ and $B$ generate the same state, then they are related to each other via \cref{eq:gauge_1}. 


\begin{theorem}[Fundamental theorem of injective MPS]\label{thm:fundamental}
    Let $V_A, V_B$ be two vector spaces and $\mathcal{H}$ be a Hilbert space with basis $\mathcal{B} = \{\ket{0},\ket{1},\dots \ket{d-1}\}$. Let $A\in \End(V_A)\otimes \mathcal{H}$, $A = \sum_{i\in \mathcal{B}} A_i \otimes \ket{i}$, and $B\in \End(V_B)\otimes \mathcal{H}$, $B = \sum_{i\in \mathcal{B}} B_i \otimes \ket{i}$, be two injective MPS tensors such that both of their injectivity length is at least $n$. If $\mathfrak{M}_k(A) = \mathfrak{M}_k(B)$ for some $k\geq 2n+1$,  then $\exists X: V_B \leftarrow V_A$ invertible, unique up to a multiplicative constant, such that 
    \begin{equation*}
       B_i = X A_i X^{-1}, \quad \forall i = \{0,1,\dots d-1\}.
    \end{equation*}
\end{theorem}

\begin{proof}
  Let us write $\mathfrak{M}_k(A) = \mathfrak{M}_k(B)$ explicitly:
  \begin{equation*}
    \sum_{i\in \mathcal{B}^k} \tr\left\{A_{i_1} A_{i_2} \dots A_{i_k}\right\} \ket{i_1 i_2 \dots i_k} = 
    \sum_{i\in \mathcal{B}^k} \tr\left\{B_{i_1} B_{i_2} \dots B_{i_k}\right\} \ket{i_1 i_2 \dots i_k}
  \end{equation*}
  Let us write $k = n+l$ with $l>n+1$ and bipartition the indices in this equation accordingly:
  \begin{equation}\label{eq:ft_thm_1}
    \sum_{\substack{i\in \mathcal{B}^n\\j\in\mathcal{B}^l}} \tr\left\{A_{i_1} \dots A_{i_n} A_{j_1} \dots A_{j_l}\right\} \ket{i_1 \dots i_n} \ket{j_1 \dots j_l}= 
    \sum_{\substack{i\in \mathcal{B}^n\\j\in\mathcal{B}^l}} \tr\left\{B_{i_1} \dots B_{i_n} B_{j_1} \dots B_{j_l}\right\} \ket{i_1 \dots i_n} \ket{j_1 \dots j_l}.
  \end{equation}
  Let $X\in \End(V_A)$ be arbitrary. From the injectivity of the tensor $A$, using \cref{thm:injectivity_equivalent}, we obtain that there is a linear functional $f:\mathcal{H}^{\otimes n}\to \mathbb{C}$ such that 
  \begin{equation*}
    X = \sum_{i\in\mathcal{B}^n} A_{i_1} \dots A_{i_n} \cdot \scalprod{f}{i_1 \dots i_n}.
  \end{equation*}
  Let us fix this $f$ and write 
  \begin{equation*}
    Y = \sum_{i\in\mathcal{B}^n} B_{i_1} \dots B_{i_n} \cdot \scalprod{f}{i_1 \dots i_n}, \quad Y\in\End(V_B).
  \end{equation*}
  Applying the linear map $f\otimes\id: \mathcal{H}^{\otimes n} \otimes \mathcal{H}^{\otimes l} \to \mathcal{H}^{\otimes l}$ on \cref{eq:ft_thm_1} we conclude thus that
  \begin{equation*}
    \sum_{j\in\mathcal{B}^l} \tr\left\{X A_{j_1} \dots A_{j_l}\right\} \ket{j_1 \dots j_l}= 
    \sum_{j\in\mathcal{B}^l} \tr\left\{Y B_{j_1} \dots B_{j_l}\right\} \ket{j_1 \dots j_l}.
  \end{equation*}
  Because of the injectivity of the MPS tensor $B$, $Y$ is uniquely defined. As $X$ was arbitrary, we conclude that for all $X\in \End(V_A)$ there is a unique $Y\in \End(V_B)$ such that this equation holds. Exchanging the role of $A$ and $B$ we obtain that also for all $Y\in \End(V_B)$ exists a unique $X\in \End(V_A)$ such that this equation holds, and thus $X\mapsto Y$ is invertible. Notice that the map $X\mapsto Y$ is linear, we can thus write $Y = \sum_i L_i X R_i$, so that 
  \begin{equation*}
    \sum_{j\in\mathcal{B}^l} \tr\left\{X A_{j_1} \dots A_{j_l}\right\} \ket{j_1 \dots j_l}= 
    \sum_{j\in\mathcal{B}^l,i} \tr\left\{L_i X R_i B_{j_1} \dots B_{j_l}\right\} \ket{j_1 \dots j_l}, \quad \forall X\in \End(V_A).
  \end{equation*}
  Setting $X=\id$ we observe that $\sum_i L_i R_i\neq 0$. Through non-degeneracy of the trace, we conclude that
  \begin{equation}\label{eq:ft_thm_2}
    \sum_{j\in\mathcal{B}^l}  A_{j_1} \dots A_{j_l} \otimes  \ket{j_1 \dots j_l}= 
    \sum_{j\in\mathcal{B}^l,i}  R_i B_{j_1} \dots B_{j_l}L_i \otimes \ket{j_1 \dots j_l}.
  \end{equation}
  Let us repeat the same argument as above, but decomposing $k$ as $(n+1)+(l-1)$. We obtain that there is $\sum_i \hat R_i \otimes \hat L_i$ such that $\sum_i \hat L_i \hat R_i \neq 0$ and    
  \begin{equation*}
    \sum_{j\in\mathcal{B}^l}  A_{j_1} \dots A_{j_{l-1}} \otimes  \ket{j_1 \dots j_{l-1}}= 
    \sum_{j\in\mathcal{B}^l,i}  \hat R_i B_{j_1} \dots  B_{j_{l-1}} \hat L_i \otimes \ket{j_1 \dots j_{l-1}}.
  \end{equation*}
  Substituting this back in \cref{eq:ft_thm_2}, once for the first $l-1$ spins and once for the last $l-1$ spins, we obtain
  \begin{equation*}
      \sum_{j\in\mathcal{B}^l}  A_{j_1} \hat R_i B_{j_2} \dots B_{j_l} \hat L_i  \otimes  \ket{j_1 \dots j_l}= 
    \sum_{j\in\mathcal{B}^l}  \hat R_i B_{j_1} \dots B_{j_{l-1}} \hat L_i A_{j_l} \otimes  \ket{j_1 \dots j_l}= 
      \sum_{j\in\mathcal{B}^l,i}  R_i B_{j_1} \dots B_{j_l}L_i \otimes \ket{j_1 \dots j_l}.
  \end{equation*}
  Using that $l-1\geq n$ and injectivity of the MPS tensor $B$, we obtain
  \begin{align}
    \sum_i R_i \otimes B_j L_i = \sum_i \hat R_i \otimes \hat L_i A_j \quad \forall j, \label{eq:ft_LR1}\\
    \sum_i R_i B_j \otimes L_i = \sum_i A_j \hat R_i \otimes \hat L_i \quad \forall j \label{eq:ft_LR2}.
  \end{align}
  Let us use \cref{lem:injective_l_r_inverse} for the tensor $B$ together with the first equation:
  \begin{equation*}
     \sum_{i} R_i \otimes L_i =  \sum_{ij} R_i \otimes l_jB_j L_i = \sum_{ij} \hat R_i \otimes l_j\hat L_i A_j.
  \end{equation*}
  Linear independence of $L_i$ thus implies that $\Span\{R_i\} \subseteq \Span\{\hat R_i\}$. The same way, using \cref{lem:injective_l_r_inverse} for the tensor $A$  leads to the conclusion that $\Span\{R_i\} \supseteq \Span\{\hat R_i\}$, and thus $\Span\{R_i\} = \Span\{\hat R_i\}$. Similarly, from the second equation, we conclude then that $\Span\{L_i\} = \Span\{\hat L_i\}$. Therefore \cref{eq:ft_LR1,eq:ft_LR2} imply that there is an automorphism $L\mapsto \hat{L}$ of $\Span\{L_i\}$ and an automorphism $R\mapsto \hat{R}$ of $\Span\{R_i\}$ such that 
  \begin{align}
    B_jL = \hat{L}A_j \quad \forall j \in \mathcal{B}, \label{eq:ft_main1}\\
    A_jR = \hat R B_j \quad \forall j \in \mathcal{B} \label{eq:ft_main2}
  \end{align}  
  Combining these two equations, we conclude that
  \begin{align*}
    B_j LR = \hat L A_j R = \hat L \hat R B_j \quad \forall j\in\mathcal{B},\\
    A_j RL = \hat R B_j L = \hat R \hat L A_j \quad \forall j\in\mathcal{B}.
  \end{align*}
  Iterating this equation we conclude that for any $L\in\Span\{L_i\}$ and $R\in\Span\{R_i\}$ there is $ \hat{L} \in \Span\{L_i\}$ and  $\hat{R} \in \Span\{R_i\}$ such that 
  \begin{align*}
    B_{j_1} \dots B_{j_n} LR = \hat L \hat R B_{j_1} \dots B_{j_n} \quad \forall j\in\mathcal{B}^n, \\
    A_{j_1} \dots A_{j_n} RL = \hat R \hat L A_{j_1} \dots A_{j_n} \quad \forall j\in\mathcal{B}^n.
  \end{align*}
  Injectivity of the tensors $A$ and $B$ imply then that for all 
  \begin{align*}
    X LR = \hat L \hat R X \quad \forall X\in \End(V_B) \\
    Y RL = \hat R \hat L Y \quad \forall Y\in \End(V_A),
  \end{align*}
  This directly implies that $LR = \hat{L}\hat{R} \propto \id_{V_B}$, and thus $LR\propto \id_{V_B}$ for any $L\in\Span\{L_i\}$ and $R\in \Span\{R_i\}$. Similarly, $RL\propto \id_{V_A}$ for any $L\in\Span\{L_i\}$ and $R\in \Span\{R_i\}$.  As $\sum_i L_i R_i \neq 0$, there is $L\in \Span\{L_i\}$ and $R\in \Span\{R_i\}$ such that $LR\neq 0$. This means that $RL\neq 0$ neither, and thus $L$ is invertible. As $LR \propto \id$ for all $R\in \Span\{R_i\}$, this implies that $R\propto L^{-1}$, and thus $\Span\{R_i\}$ is one dimensional (spanned by $L^{-1}$), so $\Span\{L_i\}$ is also one dimensional, spanned by $L$. Finally \cref{eq:ft_main1} implies that $B_j = LA_j B^{-1}$.
\end{proof}


\paragraph{Examples.} Let us consider some examples where the theorem does NOT apply. We keep the state in the examples simple: we will consider different MPS descriptions of the product state $\ket{0}^{\otimes n}$. These representations will not meet the requirements of \cref{thm:fundamental} as at least one of the MPS tensors is not injective. Consequently, the fundamental theorem does not apply, and in fact, the different MPS tensors are not related to each other by a basis transformation. First, one can consider the ``canonical'' way to represent it as an MPS:
\begin{equation*}
  A_0 = 1, \quad 
  A_1 = 0;
\end{equation*}
again, these matrices are $1\times 1$, the MPS has bond dimension 1. This is an injective MPS description of the state. The same state admits another description that is trivially the same, yet it is non-injective:
\begin{equation*}
  B_0 = \left(\begin{matrix}
    1 & 0 \\ 0 & 0 
  \end{matrix}\right), \quad 
  B_1 = \left(\begin{matrix}
    0 & 0 \\ 0 & 0 
  \end{matrix}\right).
\end{equation*}
As the MPS $B$ is non-injective (despite the fact that it describes a state that can be represented by an injective MPS), the fundamental theorem does not apply; in fact, the two MPS tensors are not related to each other with a basis transformation, as they have different bond dimensions. (Remark: one can still relate the two tensors in a way -- there are different versions of the fundamental theorem that apply in this situation.) This example can be generalized to 
\begin{equation*}
  C_0 = \ket{w}\bra{v}, \quad 
  C_1 = 0,
\end{equation*}
where $\scalprod{v}{w}=1$. In fact, if $N$ is a nilpotent matrix (and thus $\tr N^n = 0$ for all $n$), then if $\bra{v} N \ket{w} = 0$,  
\begin{equation*}
  D_0 = \ket{w}\bra{v}, \quad 
  D_1 = N,
\end{equation*}
also describes $\ket{0}^{\otimes n}$. 

\subsection{Structure of MPS}

In this section we will try to get an understanding of MPS that fail to be injective. Previously we have argued that most MPS tensors are injective, so why do we care? Mostly because when investigating topological order in 2D systems we will encounter MPS (on the boundary of the state) that are inherently non-injective. In the purely 1D setup, you might think of symmetry breaking: for example the Hamiltonian defined by $H = - \sum_i Z_i Z_{i+1}$ (the Hamiltonian is defined on $N$ particles arranged around a circle, the sum goes from $0$ to $N-1$ with $N\equiv 0$, and $Z_i = \id^{\otimes i}\otimes Z \otimes \id^{N-1-i}$) has 
ground space spanned by $\ket{0}^{\otimes n}$ and $\ket{1}^{\otimes n}$. A particular (actually physically not relevant\footnote{Irrelevant because if you consider a small local (i.e.\ sum of local operators) perturbation, such as $\lambda \cdot \sum_i Z_i$, the ground state becomes either $\ket{1}^{\otimes n}$ if $\lambda >0$ or $\ket{0}^{\otimes n}$ if $\lambda<0$, i.e.\ the global superposition is unstable under local perturbations, so you can't observe this state.}) ground state is the GHZ state: $\tfrac{1}{\sqrt{2}}(\ket{0}^n + \ket{1}^{\otimes n})$. An the MPS generating this state is defined by the matrices
\begin{equation*}
  A_0 = \left(\begin{matrix}
    1 & 0 \\ 0 & 0 
  \end{matrix}\right), \quad 
  A_1 = \left(\begin{matrix}
    0 & 0 \\ 0 & 1 
  \end{matrix}\right).
\end{equation*}
We have seen that this MPS is not injective. While it is trivial to check this, let us try to understand the structure of the MPS. Notice that the projector $P=\ket{0}\bra{0}$ (as well as the projector $1-P = \ket{1}\bra{1}$) commutes with the matrices $A_i$. In particular, 
\begin{align*}
  \mathfrak{M}_n(A) &= \sum_i \tr\{A_{i_1} \dots A_{i_n} \ket{0}\bra{0} \} + \sum_i \tr\{A_{i_1} \dots A_{i_n} \ket{1}\bra{1}\} \ket{i_1\dots i_n}= \\
                    &= \sum_i \bra{0}A_{i_1} \ket{0}\dots \bra{0}A_{i_n} \ket{0} + \sum_i \bra{1}A_{i_1}\ket{1} \dots \bra{1}A_{i_n} \ket{1} \cdot \ket{i_1\dots i_n} = \\
                    &= \ket{0 0\dots 0} + \ket{11\dots 1}. 
\end{align*}
This structure can be generalized; in fact, it is not needed that the projector commutes with $A_i$, it is enough that $A_i P = PA_i P$. For example, the MPS defined by the matrices
\begin{equation*}
  A_0 = \left(\begin{matrix}
    1 & 1 \\ 0 & 0 
  \end{matrix}\right), \quad 
  A_1 = \left(\begin{matrix}
    0 & 0 \\ 0 & 1 
  \end{matrix}\right),
\end{equation*}
still generates the GHZ state because of the same reason, but here $A_i P \neq  PA_i$ due to the presence of the entry above the diagonal. More generally, the following is true:

\begin{lemma}\label{lem:decompose}
  Let $V$ be a vector space and $\mathcal{H}$ be a Hilbert space with basis $\mathcal{B} = \{\ket{0},\ket{1},\dots \ket{d-1}\}$. Let $A\in \End(V)\otimes \mathcal{H}$ be an MPS tensor, $A = \sum_{i\in\mathcal{B}} A_i \otimes \ket{i}$. Let $P$ be a projector, $P\neq0$, $P\neq \id$. Assume that $A_{i} P= PA_{i} P$ holds for all $i\in\mathcal{B}$. Then the MPS generated by the tensor $A$ decomposes into a sum of two smaller bond dimensional MPS.
\end{lemma}

\begin{proof}
We can write
  \begin{equation*}
    \mathfrak{M}_n(A) = \sum_i \tr\{A_{i_1} \dots A_{i_n} P\} + \sum_i \tr\{A_{i_1} \dots A_{i_n} (1-P)\}.
  \end{equation*}
  The equation $A_i P = PA_i P$ is equivalent to the equation $(1-P)A_i = (1-P) A_i (1-P)$, and thus 
  \begin{equation*}
    \mathfrak{M}_n(A) = \sum_i \tr\{A_{i_1} \dots A_{i_n} P A_{i_{n-1}} P\} + \sum_i \tr\{A_{i_1} (1-P) A_{i_2} \dots A_{i_n} (1-P)\}.
  \end{equation*}
  Continuing, we obtain 
  \begin{equation*}
    \mathfrak{M}_n(A) = \sum_i \tr\{A_{i_1}P \dots PA_{i_n} P A_{i_{n-1}} P\} + \sum_i \tr\{A_{i_1} (1-P) A_{i_2}(1-P) \dots (1-P)A_{i_n} (1-P)\},
  \end{equation*}
  i.e., $\mathfrak{M}_n(A) = \mathfrak{M}_n(B) + \mathfrak{M}_n(C)$, where $B= \sum_i PA_i P \otimes \ket{i}$ and $C = \sum_i (1-P) A_i (1-P)\otimes \ket{i}$. Notice now that these two MPS tensors can be written as smaller bond dimensional MPS: for example, if $P = UW$ with $U:\End(V)\leftarrow \End(V')$ and $W:\End(V')\leftarrow End(V)$, with $\dim(V') = rank(P) = r$, then the MPS tensor $B' = \sum_i WA_iU \otimes \ket{i}$ describes the same state as $B$, but its bond dimension is only $rank(P)$. Similarly, the MPS defined by the MPS tensor $C$ can also be described by another MPS tensor $C'$ that has bond dimension $\dim(V)-rank(P)$.
\end{proof}


Given an MPS we can try to find an invariant subspace (i.e.\ projector such that $A_i P = PA_iP$ for all $i$), and decompose the MPS into two smaller bond dimensional MPS. We can repeat this procedure, until we arrive at MPS where we cannot find anymore such projectors. Do we get a decomposition of the MPS into a sum of injective MPS? The answer is no!  As an example, consider the antiferromagnetic Ising model, $H = \sum_i Z_i Z_{i+1}$. For even system size, this Hamiltonian has a two-fold degenerate ground space spanned by $\ket{01010\dots 01}$ and $\ket{1010 \dots 10}$ (what happens at odd system size?). A particular state in this subspace is the Néel state, $\tfrac{1}{\sqrt{2}}(\ket{01010\dots 01}+\ket{1010 \dots 10})$. An MPS generating this state (up to normalization) is 
\begin{equation*}
  A_0 = \left(\begin{matrix}
    0 & 1 \\ 0 & 0 
  \end{matrix}\right), \quad 
  A_1 = \left(\begin{matrix}
    0 & 0 \\ 1 & 0 
  \end{matrix}\right).
\end{equation*}
This MPS is zero for all odd system sizes: $\mathfrak{M}_{2k+1}(A) = 0$.  For even system sizes, however, note that
\begin{equation*}
  A_0 A_0 = 0, \quad 
  A_1 A_1 = 0, \quad 
  A_0 A_1 = \left(\begin{matrix}
    1 & 0 \\ 0 & 0 
  \end{matrix}\right), \quad 
  A_1 A_0 = \left(\begin{matrix}
    0 & 0 \\ 0 & 1 
  \end{matrix}\right),
\end{equation*}
and thus $A_i A_jP = P A_i A_j P$ for all $i,j$, both with $P = \ket{0}\bra{0}$ and with $P = \ket{1}\bra{1}$. We can thus repeat the same decomposition as for the GHZ state.

The same phenomenon can occur for longer length, i.e.\ one has to find all $n$ and projectors $P$ such that
\begin{equation}\label{eq:invariant_projector_n}
  A_{i_1} A_{i_2} \dots A_{i_n} P = P  A_{i_1} A_{i_2} \dots A_{i_n} P. 
\end{equation}
If there is such $n$ and $P$, then, after blocking (i.e.\ for system size $k$ such that $n|k$), the MPS will decompose into the sum of smaller bond dimensional MPS (and in fact, as in the previous example, it is zero for any system size $k$ such that $k\nmid n$). 

Finally if there is no $n$ and non-trivial (i.e.\ not $0$ or $\id$) projector $P$ satisfying \cref{eq:invariant_projector_n}, we can conclude that the MPS tensor is injective. In fact, to find such a projector, one does not have to check for all possible system sizes only at most $D^4$, where $D$ is the bond dimension. To summarize:
\begin{theorem}[Decomposition of MPS]
  Let $A$ be an injective MPS tensor defined by matrices $(A_i)_{i\in I}$. Then either there exsits $n\in \mathbb{N}$, $n\leq D^4$, and a projector $P$, $P\neq 0$ and $P\neq \id$, such that 
  \begin{equation*}
    A_{i_1} A_{i_2} \dots A_{i_n} P = P  A_{i_1} A_{i_2} \dots A_{i_n} P, 
  \end{equation*}
  or the MPS tensor is injective. If there is such $n$ and $P$, then for any system size $k$ such that $n|k$, 
  \begin{equation*}
    \mathfrak{M}_k(A) =     \mathfrak{M}_k(PAP) +     \mathfrak{M}_k((1-P)A(1-P)),
  \end{equation*} 
  where $PAP$ ($(1-P)A(1-P)$) denotes the MPS tensor defined by matrices $(PA_iP)_{i\in I}$ (resp. $((1-P)A_i(1-P))_{i\in I}$).  
\end{theorem}

We do not prove this theorem right now. Instead we learn about a related concept, transfer matrices.



\appendix

\section{Facts}

\begin{definition}[Non-degenerate bilinear functional]\label{def:nondegen_bili_fcnl}
  Let $W$ be a vector space, and $\omega: W\times W\to \mathbb{C}$ be a bilinear functional.
  We say that $\omega$ is non-degenerate if $\omega(v,w) = 0$ $\forall w\in W$ implies $v=0$ and $\omega(v,w) = 0$ $\forall v\in W$ implies $w=0$.
\end{definition}

\begin{fact}\label{fact:tr_nondegen}
  Let $V$ be a vector space, and let $\omega: \End(V)\times\End(V)\to \mathbb{C}$, $\omega(X,Y)= \tr(XY)$. Then $\omega$ is a non-degenerate bilinear functional.
\end{fact}


\begin{fact}
  Let $W$ be a vector space, and let $\omega: W\times W\to \mathbb{C}$ be a non-degenerate bilinear functional. Let $U\subsetneq W$. Then $\exists v\in W$, $v\neq 0$, such that  $\omega(v,u) =0$ $\forall u\in U$.
\end{fact}

\begin{proof}
   Let $\mathcal{B}$ be a basis of $U$ and consider the linear map $W\to U$, $v \mapsto \sum_{u\in \mathcal{B}} \omega(v,u) \cdot u$. As $\dim(U) < \dim(W)$, this map has a non-trivial kernel. As $\mathcal{B}$ consists of linearly independent vectors, any non-zero $v$ from the kernel satisfies $\omega(v,u) = 0$ $\forall u\in\mathcal{B}$, and thus, as $\Span \mathcal{B} = U$, also $\omega(v,u) = 0$ $\forall u \in U$.
    
\end{proof}





\end{document}
